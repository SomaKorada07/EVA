{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Assignment_4_VanillaNetwork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85PBbEs-jTv0",
        "colab_type": "text"
      },
      "source": [
        "#VANILLA NETWORK\n",
        "\n",
        "\n",
        "*   Will keep the parameters count less than 15k as it is a constraint for the assignment.\n",
        "*   Will keep the same batch size - 32.\n",
        "*   Will keep the Learning Rate as default one.\n",
        "*   Will keep the optimizer same as 'adam'.\n",
        "*   Will run for more epochs (say 50) to see the capacity of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "b8ca6b2d-5423-42b1-9bf0-d707715e445d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "# Installing Keras which is open-source neural-network library written in Python.\n",
        "!pip install -q keras\n",
        "\n",
        "# Importing the keras library.\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing NumPy (Numerical Python) which is a library consisting of multidimensional array objects and a collection of routines for processing those arrays. It also gives an alias to the library.\n",
        "import numpy as np\n",
        "\n",
        "# There are two main types of models available in Keras: the Sequential model and the Model class used with the functional API.\n",
        "# Sequential model is a linear stack of layers. Importing Sequential model from Keras.\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Importing different layers from Keras.\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "# Importing the utils library of Keras.\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Importing the callbacks of Keras.\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# MNIST is a database of handwritten digits. It is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. Importing MNIST dataset from Keras.\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "dbf3dda8-5c8f-4f43-b5df-bb5d2cf7dab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Loading the MNIST 60000 Training and 10000 Test data into respective numpy arrays\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "881e7ff6-7b57-4988-bd5a-0bd4fc215794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "# Printing the shape of the Training data\n",
        "print (X_train.shape)\n",
        "\n",
        "# Matplotlib is a plotting library for Python. Pyplot is a collection of command style functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc.\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Sets the backend of matplotlib to 'inline' backend. With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it.\n",
        "%matplotlib inline\n",
        "\n",
        "# Renders the image.\n",
        "plt.imshow(X_train[7777])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff84bd12080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaping the Training and Test data to add the channel parameter as the input to Conv2D layer is expected to be of shape (img_rows, img_cols, num_channels) if data_format=\"channels_last\" which is default.\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing the Training and Test values\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "f87abd9b-0230-44d5-be4c-94880f77813f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Printing the first 10 labelled Training data\n",
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "# np.utils.to_categorical is used to convert array of labelled data (from 0 to nb_classes-1) to one-hot vector.\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "3c34053b-1a88-4681-fe29-1e5702062796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Printing the first 10 labelled Training data after converting to one-hot vector.\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "18b50973-0655-47bd-ae33-06d90309d3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8, 3, input_shape=(28,28,1), use_bias=False)) # RF - 3X3, O/P - 26x26\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(14, 3, use_bias=False)) # RF - 5X5, O/P - 24x24\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 3, use_bias=False)) # RF - 7X7, O/P - 22x22\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(8, 1, use_bias=False))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides=None, padding='valid', data_format=None)) # RF - 14X14, O/P - 11x11\n",
        "\n",
        "model.add(Convolution2D(8, 3, use_bias=False)) # RF - 16X16, O/P - 9X9\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(14, 3, use_bias=False)) # RF - 16X16, O/P - 7X7\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 3, use_bias=False)) # RF - 18X18, O/P - 5X5\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, use_bias=False))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 5, use_bias=False)) # RF - 20X20, O/P - 5X5\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "3c5820fb-4b6a-469c-a6eb-7a4177c1b404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         72        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 14)        1008      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 16)        2016      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 22, 22, 8)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 8)           576       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 14)          1008      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 16)          2016      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 10)          160       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 10)          2500      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 9,484\n",
            "Trainable params: 9,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "# Loss function is one of the arguments required for compiling a model. categorical_crossentropy loss function is used if the targets are one-hot encoded.\n",
        "# Optimizer is one of the arguments required for compiling a model. Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n",
        "# A metric is a function that is used to judge the performance of your model.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "714e7f32-6490-46ba-82da-4abf162f7517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1856
        }
      },
      "source": [
        "# Training the model for 50 epochs using batch_size of 32.\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=50, verbose=1,validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 14s 238us/step - loss: 0.2388 - acc: 0.9243 - val_loss: 0.0757 - val_acc: 0.9764\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0869 - acc: 0.9741 - val_loss: 0.0577 - val_acc: 0.9803\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0669 - acc: 0.9794 - val_loss: 0.0495 - val_acc: 0.9847\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0562 - acc: 0.9829 - val_loss: 0.0596 - val_acc: 0.9815\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0484 - acc: 0.9850 - val_loss: 0.0405 - val_acc: 0.9856\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0424 - acc: 0.9868 - val_loss: 0.0340 - val_acc: 0.9886\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0383 - acc: 0.9882 - val_loss: 0.0386 - val_acc: 0.9878\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.0342 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9880\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0305 - acc: 0.9903 - val_loss: 0.0395 - val_acc: 0.9883\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0291 - acc: 0.9906 - val_loss: 0.0320 - val_acc: 0.9903\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0268 - acc: 0.9916 - val_loss: 0.0337 - val_acc: 0.9885\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0261 - acc: 0.9914 - val_loss: 0.0358 - val_acc: 0.9892\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0231 - acc: 0.9922 - val_loss: 0.0345 - val_acc: 0.9896\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0224 - acc: 0.9929 - val_loss: 0.0435 - val_acc: 0.9861\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0205 - acc: 0.9937 - val_loss: 0.0340 - val_acc: 0.9889\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0205 - acc: 0.9932 - val_loss: 0.0359 - val_acc: 0.9899\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0177 - acc: 0.9941 - val_loss: 0.0333 - val_acc: 0.9905\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0416 - val_acc: 0.9889\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0168 - acc: 0.9944 - val_loss: 0.0422 - val_acc: 0.9877\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0411 - val_acc: 0.9887\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0338 - val_acc: 0.9906\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0151 - acc: 0.9947 - val_loss: 0.0343 - val_acc: 0.9915\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.0359 - val_acc: 0.9916\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0142 - acc: 0.9955 - val_loss: 0.0332 - val_acc: 0.9900\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0383 - val_acc: 0.9894\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0127 - acc: 0.9957 - val_loss: 0.0400 - val_acc: 0.9895\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0437 - val_acc: 0.9876\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0410 - val_acc: 0.9901\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0397 - val_acc: 0.9898\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0122 - acc: 0.9956 - val_loss: 0.0361 - val_acc: 0.9905\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0437 - val_acc: 0.9890\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0498 - val_acc: 0.9880\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0103 - acc: 0.9966 - val_loss: 0.0434 - val_acc: 0.9892\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.0603 - val_acc: 0.9867\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.0468 - val_acc: 0.9891\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0452 - val_acc: 0.9897\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0609 - val_acc: 0.9877\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0431 - val_acc: 0.9900\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0493 - val_acc: 0.9901\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0435 - val_acc: 0.9906\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0500 - val_acc: 0.9902\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0451 - val_acc: 0.9906\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0484 - val_acc: 0.9894\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0524 - val_acc: 0.9900\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.0537 - val_acc: 0.9894\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0086 - acc: 0.9969 - val_loss: 0.0476 - val_acc: 0.9904\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0455 - val_acc: 0.9904\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0524 - val_acc: 0.9878\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0506 - val_acc: 0.9901\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0622 - val_acc: 0.9882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8955ee080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_opIwh1El43u",
        "colab_type": "text"
      },
      "source": [
        "# Best Validation Accuracy\n",
        "Best validation accuracy is at **epoch 23** - **val_acc: 0.9916**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the model on the Test data using the weights of last epoch. Returns the loss value & metrics values for the model in test mode.\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "92e13bf7-9330-4664-e51b-14e32f9b306f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Printing the evaluation result\n",
        "print(score);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.062234554029460425, 0.9882]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates output predictions for the input samples.\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "233493c3-6bc7-46b9-ec76-000f637452c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# Printing the outputs. y_pred results do not look correct.\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.65895374e-24 1.78195487e-19 1.11880360e-13 2.95407275e-12\n",
            "  5.66156359e-22 6.45947731e-20 0.00000000e+00 1.00000000e+00\n",
            "  4.37219429e-16 2.00083645e-15]\n",
            " [7.21730305e-17 6.31491062e-13 1.00000000e+00 8.41569316e-19\n",
            "  2.02793223e-21 8.35338358e-20 1.08539861e-15 4.81838361e-20\n",
            "  2.00482404e-12 1.44996961e-25]\n",
            " [1.93030245e-11 9.99999881e-01 1.65916170e-09 1.66336146e-11\n",
            "  8.13772782e-09 1.12904949e-07 6.58331289e-12 1.02050111e-08\n",
            "  6.94706470e-09 1.25984531e-12]\n",
            " [1.00000000e+00 2.53710832e-18 9.68629482e-11 4.03132284e-11\n",
            "  4.81969140e-19 1.05306305e-10 4.32666774e-08 4.96653879e-13\n",
            "  9.98983001e-14 1.33855644e-11]\n",
            " [1.09769957e-21 1.30612457e-20 2.76111730e-17 2.76718370e-22\n",
            "  1.00000000e+00 1.06401805e-25 6.47682355e-20 1.44701021e-22\n",
            "  4.83118529e-16 3.37651542e-08]\n",
            " [1.20240120e-11 1.00000000e+00 4.80380846e-10 5.24084031e-13\n",
            "  8.07443090e-09 5.57122681e-11 7.17235397e-15 3.30143948e-08\n",
            "  7.75756459e-10 4.21618645e-14]\n",
            " [8.09275988e-36 1.85191175e-15 1.30062163e-26 3.03264055e-27\n",
            "  1.00000000e+00 1.62464324e-27 0.00000000e+00 1.75577380e-12\n",
            "  5.66538251e-16 1.89484374e-13]\n",
            " [6.08206883e-15 7.51226555e-13 2.07606068e-11 1.16543939e-08\n",
            "  1.39668016e-04 1.37715039e-11 1.43679382e-20 1.53285981e-07\n",
            "  3.17056004e-09 9.99860168e-01]\n",
            " [2.40710079e-07 7.78530336e-22 9.67559383e-15 5.28698166e-16\n",
            "  4.99115302e-19 9.29825246e-01 7.00390115e-02 1.75544014e-24\n",
            "  1.35565904e-04 2.18186709e-15]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "047a9430-ebf2-4b61-c576-5762b12a0ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_1'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 2, 4\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwcAAALyCAYAAACPcKhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHeUAAABIohwAAAAd5QAAAEiS/B/UhZeDfrxwVgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x864 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}