{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Assignment_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MWAp4iFtVYJ",
        "colab_type": "text"
      },
      "source": [
        "#HEADER NOTE\n",
        "\n",
        "*   Will keep the parameters count within 15k which is a constraint for the assignment.\n",
        "*   Will continue to keep the batch size to 128.\n",
        "*   Will keep the Learning Rate as default one.\n",
        "*   Will keep the optimizer same as 'adam'.\n",
        "*   Will add Dropouts to reduce the gap between Training accuracy and Validation accuracy.\n",
        "*   Changing the position of Dropouts from after convolution layers to before BatchNormalizations. - *an improvement over the previous network* \n",
        "*   Introduce LR Scheduler to change LR (reduce by 10%) every 10 epochs. - *an improvement over the previous network*\n",
        "*   Will add BatchNormalizations before every convolution layer except the first one.\n",
        "*   Will run for more epochs (say 50) to see the capacity of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "1d47f8da-65cf-4c41-e28a-33f6ef6456f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "# Installing Keras which is open-source neural-network library written in Python.\n",
        "!pip install -q keras\n",
        "\n",
        "# Importing the keras library.\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing NumPy (Numerical Python) which is a library consisting of multidimensional array objects and a collection of routines for processing those arrays. It also gives an alias to the library.\n",
        "import numpy as np\n",
        "\n",
        "# There are two main types of models available in Keras: the Sequential model and the Model class used with the functional API.\n",
        "# Sequential model is a linear stack of layers. Importing Sequential model from Keras.\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Importing different layers from Keras.\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "# Importing the utils library of Keras.\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Importing the callbacks of Keras.\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# MNIST is a database of handwritten digits. It is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. Importing MNIST dataset from Keras.\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the MNIST 60000 Training and 10000 Test data into respective numpy arrays\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "54333b8a-6a9f-40b8-8a06-99598a0b8742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "# Printing the shape of the Training data\n",
        "print (X_train.shape)\n",
        "\n",
        "# Matplotlib is a plotting library for Python. Pyplot is a collection of command style functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc.\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Sets the backend of matplotlib to 'inline' backend. With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it.\n",
        "%matplotlib inline\n",
        "\n",
        "# Renders the image.\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe16eb4eac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaping the Training and Test data to add the channel parameter as the input to Conv2D layer is expected to be of shape (img_rows, img_cols, num_channels) if data_format=\"channels_last\" which is default.\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing the Training and Test values\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "bcd3ef65-2bc6-4b2c-f292-c687f8b5c25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Printing the first 10 labelled Training data\n",
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "# np.utils.to_categorical is used to convert array of labelled data (from 0 to nb_classes-1) to one-hot vector.\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "e3db763a-1a87-4a2c-e6af-51692fff87b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Printing the first 10 labelled Training data after converting to one-hot vector.\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "7e6c583b-9e2f-4228-d7cf-5d4ec8fb499f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "# Defining the model/network using (3,3) and (1,1) convolution layers, dropout, batchnormalization and 'relu' activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8, 3, input_shape=(28,28,1), use_bias=False)) # RF - 3X3, O/P - 26x26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.125))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 3, use_bias=False)) # RF - 5X5, O/P - 24x24\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.125))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, use_bias=False)) # RF - 7X7, O/P - 22x22\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(8, 1, use_bias=False))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides=None, padding='valid', data_format=None)) # RF - 14X14, O/P - 11x11\n",
        "\n",
        "model.add(Dropout(0.125))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(8, 3, use_bias=False)) # RF - 16X16, O/P - 9X9\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 3, use_bias=False)) # RF - 18X18, O/P - 7X7\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.125))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, use_bias=False)) # RF - 20X20, O/P - 5X5\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 1, use_bias=False)) # RF - 20X20, O/P - 5X5\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.125))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 5, use_bias=False)) # RF - 20X20, O/P - 5X5\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "282f46dd-6d4e-4fab-caab-c81760117df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1224
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         72        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 10)        720       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 16)        1440      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 22, 22, 8)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 8)           576       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 10)          720       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 16)          1440      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 10)          160       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 10)          2500      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,068\n",
            "Trainable params: 7,912\n",
            "Non-trainable params: 156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "# Loss function is one of the arguments required for compiling a model. categorical_crossentropy loss function is used if the targets are one-hot encoded.\n",
        "# Optimizer is one of the arguments required for compiling a model. Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n",
        "# A metric is a function that is used to judge the performance of your model.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "86c14444-5883-4971-cfe3-0738a19c0d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1856
        }
      },
      "source": [
        "# Training the model for 50 epochs using batch_size of 128.\n",
        "model.fit(X_train, Y_train, batch_size=128, nb_epoch=50, verbose=1,validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.5416 - acc: 0.8267 - val_loss: 0.1102 - val_acc: 0.9626\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1386 - acc: 0.9572 - val_loss: 0.0641 - val_acc: 0.9798\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.1022 - acc: 0.9686 - val_loss: 0.0452 - val_acc: 0.9852\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0826 - acc: 0.9752 - val_loss: 0.0383 - val_acc: 0.9896\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0738 - acc: 0.9770 - val_loss: 0.0365 - val_acc: 0.9885\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0629 - acc: 0.9801 - val_loss: 0.0296 - val_acc: 0.9902\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0572 - acc: 0.9823 - val_loss: 0.0276 - val_acc: 0.9903\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0535 - acc: 0.9833 - val_loss: 0.0393 - val_acc: 0.9867\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0531 - acc: 0.9830 - val_loss: 0.0284 - val_acc: 0.9913\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0488 - acc: 0.9850 - val_loss: 0.0254 - val_acc: 0.9916\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0473 - acc: 0.9856 - val_loss: 0.0264 - val_acc: 0.9915\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0441 - acc: 0.9867 - val_loss: 0.0243 - val_acc: 0.9923\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0423 - acc: 0.9863 - val_loss: 0.0309 - val_acc: 0.9908\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0385 - acc: 0.9873 - val_loss: 0.0240 - val_acc: 0.9919\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0399 - acc: 0.9870 - val_loss: 0.0245 - val_acc: 0.9919\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0389 - acc: 0.9875 - val_loss: 0.0267 - val_acc: 0.9907\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0376 - acc: 0.9878 - val_loss: 0.0240 - val_acc: 0.9926\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0371 - acc: 0.9884 - val_loss: 0.0210 - val_acc: 0.9928\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0355 - acc: 0.9887 - val_loss: 0.0211 - val_acc: 0.9934\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0359 - acc: 0.9884 - val_loss: 0.0238 - val_acc: 0.9913\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0328 - acc: 0.9895 - val_loss: 0.0270 - val_acc: 0.9913\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0338 - acc: 0.9898 - val_loss: 0.0233 - val_acc: 0.9923\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0335 - acc: 0.9888 - val_loss: 0.0240 - val_acc: 0.9927\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0313 - acc: 0.9899 - val_loss: 0.0224 - val_acc: 0.9926\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0319 - acc: 0.9900 - val_loss: 0.0222 - val_acc: 0.9929\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0292 - acc: 0.9907 - val_loss: 0.0220 - val_acc: 0.9931\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0294 - acc: 0.9901 - val_loss: 0.0228 - val_acc: 0.9929\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0301 - acc: 0.9901 - val_loss: 0.0224 - val_acc: 0.9923\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0310 - acc: 0.9900 - val_loss: 0.0203 - val_acc: 0.9928\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0296 - acc: 0.9903 - val_loss: 0.0219 - val_acc: 0.9934\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0299 - acc: 0.9905 - val_loss: 0.0218 - val_acc: 0.9928\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0296 - acc: 0.9900 - val_loss: 0.0219 - val_acc: 0.9930\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0274 - acc: 0.9907 - val_loss: 0.0209 - val_acc: 0.9937\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0280 - acc: 0.9906 - val_loss: 0.0226 - val_acc: 0.9929\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0282 - acc: 0.9914 - val_loss: 0.0205 - val_acc: 0.9939\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0224 - val_acc: 0.9937\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0273 - acc: 0.9910 - val_loss: 0.0197 - val_acc: 0.9936\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0204 - val_acc: 0.9935\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0275 - acc: 0.9910 - val_loss: 0.0216 - val_acc: 0.9928\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0266 - acc: 0.9912 - val_loss: 0.0197 - val_acc: 0.9941\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0264 - acc: 0.9914 - val_loss: 0.0236 - val_acc: 0.9926\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0267 - acc: 0.9914 - val_loss: 0.0195 - val_acc: 0.9937\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0255 - acc: 0.9915 - val_loss: 0.0206 - val_acc: 0.9933\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0256 - acc: 0.9917 - val_loss: 0.0248 - val_acc: 0.9926\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0246 - acc: 0.9920 - val_loss: 0.0198 - val_acc: 0.9935\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0250 - acc: 0.9916 - val_loss: 0.0217 - val_acc: 0.9932\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0242 - acc: 0.9921 - val_loss: 0.0206 - val_acc: 0.9936\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0241 - acc: 0.9917 - val_loss: 0.0235 - val_acc: 0.9930\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0240 - acc: 0.9920 - val_loss: 0.0216 - val_acc: 0.9938\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0242 - acc: 0.9924 - val_loss: 0.0197 - val_acc: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe14e0f0278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKu2yFxTtshn",
        "colab_type": "text"
      },
      "source": [
        "# Validation accuracy of 99.4\n",
        "Reached 99.41% validation accuracy at epoch number **40** - **val_acc: 0.9941**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the model on the Test data using the weights of last epoch. Returns the loss value & metrics values for the model in test mode.\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "6bb24c92-c557-4b6d-f631-83ff0495aa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Printing the evaluation result\n",
        "print(score);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01974223613693612, 0.994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates output predictions for the input samples.\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "57c71dcd-4984-4ef4-fd8c-1f63a91c7f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# Printing the outputs. y_pred results do not look correct.\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.35665034e-08 7.51445981e-08 8.06307298e-07 6.23318854e-08\n",
            "  6.73978295e-09 1.73100272e-08 1.22248626e-11 9.99998927e-01\n",
            "  3.77707698e-10 8.74845654e-08]\n",
            " [1.63583558e-09 9.61808155e-07 9.99989867e-01 3.65330904e-10\n",
            "  7.55255556e-08 1.86338375e-11 9.10567360e-06 2.65770461e-10\n",
            "  9.68398961e-09 1.17832217e-13]\n",
            " [6.53370247e-09 9.99979377e-01 5.92533844e-08 3.99786648e-09\n",
            "  1.81533971e-06 1.61428702e-08 1.26851205e-06 1.70885978e-05\n",
            "  2.99340172e-07 4.81906710e-08]\n",
            " [9.99880552e-01 6.55844129e-12 5.52341760e-07 1.64989231e-08\n",
            "  2.25559688e-07 1.01082229e-07 1.00101584e-04 1.93529770e-09\n",
            "  1.07516894e-06 1.72676118e-05]\n",
            " [1.08467757e-09 8.02627279e-14 2.27806888e-11 1.79930083e-12\n",
            "  9.99965668e-01 4.64177030e-10 4.32982761e-09 1.05601679e-08\n",
            "  7.04474867e-10 3.42966705e-05]\n",
            " [2.95361406e-08 9.99978185e-01 1.04779048e-07 8.26194224e-10\n",
            "  1.34770437e-06 1.45601131e-08 1.07050994e-06 1.90229148e-05\n",
            "  2.14546162e-07 4.90499801e-08]\n",
            " [2.68162168e-08 1.95427879e-06 6.80345058e-10 1.31357879e-07\n",
            "  9.89598751e-01 2.52359058e-07 2.28998018e-11 1.01818824e-02\n",
            "  4.81346433e-06 2.12082770e-04]\n",
            " [4.62768917e-08 1.23374963e-10 6.81192773e-08 9.53303854e-08\n",
            "  8.26435135e-05 4.35504433e-09 1.16702620e-10 6.49970318e-08\n",
            "  1.84680584e-06 9.99915242e-01]\n",
            " [1.44618483e-07 6.85286712e-15 5.82234301e-16 1.47445933e-09\n",
            "  2.90529215e-11 9.89450991e-01 9.97539517e-03 1.35182216e-13\n",
            "  5.65846451e-04 7.68262271e-06]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_1'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 2, 4\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}