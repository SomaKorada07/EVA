{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Assignment16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2umTZx28H9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "737ebf3a-575e-44b3-bf98-29dbed9ed41f"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pncakgSx8TCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f52f8ed1-13ae-42be-b9da-06d092abe9ab"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt8kEJTk8Vm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import sys\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po8x5piV8ZWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7eb70229-10e3-4b00-8a53-b2abf7125668"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU64W1pb8etC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzmEoz3d8gxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFRecords:   \n",
        "#   def __init__(self, out_filename, images, labels):\n",
        "#     self.out_filename = out_filename\n",
        "#     self.images = images\n",
        "#     self.labels = labels\n",
        "\n",
        "  def _int64_feature(self, value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "  def _bytes_feature(self, value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "    \n",
        "  def createDataRecord(self, out_filename, images, labels):\n",
        "\n",
        "    writer = tf.io.TFRecordWriter(out_filename)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "      feature = {\n",
        "          'image_raw': self._bytes_feature(images[i].tostring()),\n",
        "          'label': self._int64_feature(labels[i])\n",
        "      }\n",
        "\n",
        "      example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP7yJzpk8m1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantite the class\n",
        "tfRecords = TFRecords()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX90_WTT8rEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfRecords.createDataRecord('train.tfrecords', x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBx65jxg8t0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfRecords.createDataRecord('test.tfrecords', x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja1McrPD8trL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91616280-601f-4a83-f7ff-ae3dd2e1bc93"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  test.tfrecords  train.tfrecords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIyNaXva8tny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 5\n",
        "num_filter = 22\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPUaBwTZ8tkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 22, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(5):\n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HZQ_OAu8the",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_transition(input, num_filter = 22, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdHpC6P48teU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQloorlg8tbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "460bbf01-4fb9-4304-ab4c-4d49a2290902"
      },
      "source": [
        "num_filter = 22\n",
        "dropout_rate = 0.2\n",
        "l = 5\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5WtcZ_78tLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Model(inputs=[input], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKN9kXSb9D9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7zQusRy9EAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a670120-b4cd-4b65-f37c-c9b58bf16862"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 22)   594         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 22)   88          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 22)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 22)   4356        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 22)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 44)   0           conv2d[0][0]                     \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 44)   176         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 44)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 22)   8712        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 22)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 66)   0           concatenate[0][0]                \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 66)   264         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 66)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 22)   13068       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 22)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 88)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 88)   352         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 88)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 22)   17424       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 22)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 110)  0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 110)  440         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 110)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 22)   21780       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 22)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 132)  0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 132)  528         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 132)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 11)   1452        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 11)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 11)   0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 11)   44          average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 11)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 22)   2178        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 16, 16, 22)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 16, 16, 33)   0           average_pooling2d[0][0]          \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 33)   132         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 33)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 22)   6534        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 16, 16, 22)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 16, 16, 55)   0           concatenate_5[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 55)   220         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 55)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 22)   10890       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 16, 16, 22)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 77)   0           concatenate_6[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 77)   308         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 77)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 22)   15246       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 16, 16, 22)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 16, 99)   0           concatenate_7[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 99)   396         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 99)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 22)   19602       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 16, 16, 22)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 121)  0           concatenate_8[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 121)  484         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 121)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 11)   1331        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 16, 16, 11)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 11)     0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 11)     44          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 11)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 22)     2178        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 8, 8, 22)     0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 8, 8, 33)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 33)     132         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 33)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 22)     6534        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 8, 8, 22)     0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 8, 8, 55)     0           concatenate_10[0][0]             \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 55)     220         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 55)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 22)     10890       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 8, 8, 22)     0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 8, 8, 77)     0           concatenate_11[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 77)     308         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 77)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 22)     15246       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 8, 8, 22)     0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 8, 8, 99)     0           concatenate_12[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 99)     396         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 99)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 22)     19602       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 8, 8, 22)     0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 8, 8, 121)    0           concatenate_13[0][0]             \n",
            "                                                                 dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 121)    484         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 121)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 11)     1331        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 8, 8, 11)     0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 11)     0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 4, 11)     44          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 11)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 22)     2178        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 4, 4, 22)     0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 4, 4, 33)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 4, 4, 33)     132         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 33)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 22)     6534        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 4, 4, 22)     0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 4, 4, 55)     0           concatenate_15[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 4, 4, 55)     220         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 4, 55)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 4, 4, 22)     10890       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 4, 4, 22)     0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 4, 4, 77)     0           concatenate_16[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 77)     308         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 77)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 22)     15246       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 4, 4, 22)     0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 4, 4, 99)     0           concatenate_17[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 4, 4, 99)     396         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 99)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 22)     19602       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 4, 4, 22)     0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 4, 4, 121)    0           concatenate_18[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 4, 4, 121)    484         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 121)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 121)    0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 484)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           4850        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 244,848\n",
            "Trainable params: 241,548\n",
            "Non-trainable params: 3,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvLcBCDh9EDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parser(record):\n",
        "  keys_to_features = {\n",
        "      'image_raw': tf.FixedLenFeature((), tf.string),\n",
        "      'label': tf.FixedLenFeature((), tf.int64)\n",
        "  }\n",
        "  parsed = tf.parse_single_example(record, keys_to_features)\n",
        "  image = tf.decode_raw(parsed['image_raw'], tf.uint8)\n",
        "  image = tf.cast(image, tf.int32)\n",
        "  image = tf.reshape(image, [32,32,3])\n",
        "  label = tf.cast(parsed[\"label\"], tf.int32)\n",
        "  label = tf.one_hot(label, 10)\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKg91xkA9EF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset_from_TFRecord(filename):\n",
        "  dataset = tf.data.TFRecordDataset(filenames='train.tfrecords')\n",
        "  dataset = dataset.map(parser)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxAK9Qh29EI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2e6fb2dc-7f0b-4725-c702-46ae67fca8cb"
      },
      "source": [
        "dataset = get_dataset_from_TFRecord('train.tfrecords')\n",
        "dataset = dataset.batch(512)\n",
        "dataset = dataset.repeat()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUxEk0pN9ELx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = get_dataset_from_TFRecord('test.tfrecords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImRcFGDA9EO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = val_dataset.batch(512).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6AUr4yQ9ESV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c80a9504-3705-45a9-800f-885e99a8da57"
      },
      "source": [
        "model.fit(dataset, epochs=50, steps_per_epoch=30,\n",
        "          validation_data=val_dataset,validation_steps=3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Train on 30 steps, validate on 3 steps\n",
            "Epoch 1/50\n",
            "30/30 [==============================] - 13s 447ms/step - loss: 2.0428 - acc: 0.2472 - val_loss: 4.1736 - val_acc: 0.1048\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 1.7135 - acc: 0.3639 - val_loss: 2.5760 - val_acc: 0.1393\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 1.5916 - acc: 0.4103 - val_loss: 1.7385 - val_acc: 0.3561\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 6s 193ms/step - loss: 1.4738 - acc: 0.4544 - val_loss: 1.5709 - val_acc: 0.4336\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 1.3850 - acc: 0.4922 - val_loss: 1.6347 - val_acc: 0.3874\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 1.3203 - acc: 0.5172 - val_loss: 2.0337 - val_acc: 0.3112\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 1.2602 - acc: 0.5400 - val_loss: 1.8116 - val_acc: 0.3932\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 1.2197 - acc: 0.5585 - val_loss: 2.1918 - val_acc: 0.3522\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 1.1542 - acc: 0.5805 - val_loss: 2.3102 - val_acc: 0.3438\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 1.1218 - acc: 0.5962 - val_loss: 1.9368 - val_acc: 0.4303\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 1.0954 - acc: 0.6076 - val_loss: 1.9424 - val_acc: 0.4349\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 1.0499 - acc: 0.6182 - val_loss: 2.0882 - val_acc: 0.3997\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 1.0330 - acc: 0.6308 - val_loss: 1.3158 - val_acc: 0.5605\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 1.0088 - acc: 0.6345 - val_loss: 1.3705 - val_acc: 0.5443\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.9761 - acc: 0.6479 - val_loss: 1.1032 - val_acc: 0.6126\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 0.9630 - acc: 0.6508 - val_loss: 1.0767 - val_acc: 0.6315\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 0.9272 - acc: 0.6660 - val_loss: 0.9599 - val_acc: 0.6667\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.9170 - acc: 0.6714 - val_loss: 1.0982 - val_acc: 0.6309\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.9042 - acc: 0.6758 - val_loss: 1.1892 - val_acc: 0.6146\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.8725 - acc: 0.6886 - val_loss: 1.1777 - val_acc: 0.6159\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.8624 - acc: 0.6927 - val_loss: 1.3075 - val_acc: 0.5931\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.8339 - acc: 0.7031 - val_loss: 1.0290 - val_acc: 0.6589\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.8274 - acc: 0.7047 - val_loss: 1.4550 - val_acc: 0.5469\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.8099 - acc: 0.7102 - val_loss: 1.4803 - val_acc: 0.5833\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.7962 - acc: 0.7154 - val_loss: 1.3975 - val_acc: 0.5814\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.8036 - acc: 0.7117 - val_loss: 1.0314 - val_acc: 0.6732\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.7688 - acc: 0.7246 - val_loss: 1.3359 - val_acc: 0.6016\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.7641 - acc: 0.7299 - val_loss: 0.8781 - val_acc: 0.7122\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.7587 - acc: 0.7294 - val_loss: 0.9889 - val_acc: 0.6647\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.7330 - acc: 0.7345 - val_loss: 0.7333 - val_acc: 0.7493\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.7367 - acc: 0.7389 - val_loss: 0.8158 - val_acc: 0.7135\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.7373 - acc: 0.7406 - val_loss: 0.9359 - val_acc: 0.6882\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.7055 - acc: 0.7481 - val_loss: 0.8286 - val_acc: 0.7122\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 0.7190 - acc: 0.7415 - val_loss: 0.8527 - val_acc: 0.7181\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.6985 - acc: 0.7548 - val_loss: 1.1902 - val_acc: 0.6380\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6956 - acc: 0.7539 - val_loss: 0.9963 - val_acc: 0.6803\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6821 - acc: 0.7571 - val_loss: 0.7241 - val_acc: 0.7480\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 0.6743 - acc: 0.7616 - val_loss: 0.9523 - val_acc: 0.6992\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.6800 - acc: 0.7600 - val_loss: 0.8916 - val_acc: 0.7292\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6478 - acc: 0.7694 - val_loss: 0.8669 - val_acc: 0.7207\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.6576 - acc: 0.7677 - val_loss: 0.9339 - val_acc: 0.7122\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6537 - acc: 0.7695 - val_loss: 0.8052 - val_acc: 0.7337\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6310 - acc: 0.7735 - val_loss: 0.6866 - val_acc: 0.7559\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.6387 - acc: 0.7719 - val_loss: 0.6638 - val_acc: 0.7663\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6276 - acc: 0.7780 - val_loss: 0.8378 - val_acc: 0.7155\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6165 - acc: 0.7794 - val_loss: 0.6829 - val_acc: 0.7624\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.6201 - acc: 0.7800 - val_loss: 0.6518 - val_acc: 0.7799\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.6169 - acc: 0.7803 - val_loss: 1.0482 - val_acc: 0.6745\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.6022 - acc: 0.7864 - val_loss: 0.8107 - val_acc: 0.7214\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.5980 - acc: 0.7897 - val_loss: 0.8611 - val_acc: 0.7305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1584099320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcYr74Xh9fly",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75577584-5360-4e84-e127-90e17ff630a7"
      },
      "source": [
        "model.fit(dataset, epochs=50, steps_per_epoch=30,\n",
        "          validation_data=val_dataset,validation_steps=3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Train on 30 steps, validate on 3 steps\n",
            "Epoch 1/50\n",
            "30/30 [==============================] - 9s 287ms/step - loss: 0.5729 - acc: 0.7946 - val_loss: 1.0485 - val_acc: 0.6790\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.5984 - acc: 0.7891 - val_loss: 0.7576 - val_acc: 0.7643\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.5993 - acc: 0.7843 - val_loss: 0.7574 - val_acc: 0.7422\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.5672 - acc: 0.8000 - val_loss: 0.6691 - val_acc: 0.7812\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5866 - acc: 0.7930 - val_loss: 1.0529 - val_acc: 0.6849\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5810 - acc: 0.7954 - val_loss: 0.7898 - val_acc: 0.7578\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5607 - acc: 0.8051 - val_loss: 0.8046 - val_acc: 0.7500\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.5602 - acc: 0.7992 - val_loss: 0.6585 - val_acc: 0.7845\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.5580 - acc: 0.8032 - val_loss: 0.8264 - val_acc: 0.7422\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.5465 - acc: 0.8045 - val_loss: 0.5907 - val_acc: 0.8073\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.5547 - acc: 0.8029 - val_loss: 0.7860 - val_acc: 0.7435\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5544 - acc: 0.8074 - val_loss: 0.7920 - val_acc: 0.7598\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5476 - acc: 0.8075 - val_loss: 0.5445 - val_acc: 0.8040\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5239 - acc: 0.8128 - val_loss: 0.9007 - val_acc: 0.7311\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.5396 - acc: 0.8099 - val_loss: 0.6999 - val_acc: 0.7767\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.5385 - acc: 0.8120 - val_loss: 0.7588 - val_acc: 0.7546\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5145 - acc: 0.8177 - val_loss: 0.5175 - val_acc: 0.8190\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5269 - acc: 0.8109 - val_loss: 0.6755 - val_acc: 0.7780\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5277 - acc: 0.8185 - val_loss: 1.0568 - val_acc: 0.7142\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.5014 - acc: 0.8257 - val_loss: 0.4918 - val_acc: 0.8275\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5147 - acc: 0.8143 - val_loss: 0.6318 - val_acc: 0.7871\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5148 - acc: 0.8167 - val_loss: 1.3836 - val_acc: 0.6374\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.5122 - acc: 0.8182 - val_loss: 0.6912 - val_acc: 0.7812\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.5006 - acc: 0.8234 - val_loss: 0.8150 - val_acc: 0.7292\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5038 - acc: 0.8254 - val_loss: 0.5964 - val_acc: 0.8021\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5010 - acc: 0.8236 - val_loss: 0.7788 - val_acc: 0.7643\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.4810 - acc: 0.8262 - val_loss: 0.7524 - val_acc: 0.7773\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.5012 - acc: 0.8215 - val_loss: 0.6087 - val_acc: 0.7982\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.4989 - acc: 0.8230 - val_loss: 1.1740 - val_acc: 0.6615\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4779 - acc: 0.8316 - val_loss: 1.1795 - val_acc: 0.6712\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4949 - acc: 0.8242 - val_loss: 0.7612 - val_acc: 0.7689\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4816 - acc: 0.8299 - val_loss: 0.7460 - val_acc: 0.7832\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 0.4821 - acc: 0.8289 - val_loss: 0.6123 - val_acc: 0.8027\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4851 - acc: 0.8285 - val_loss: 0.7216 - val_acc: 0.7702\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4791 - acc: 0.8321 - val_loss: 0.6025 - val_acc: 0.8053\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4774 - acc: 0.8327 - val_loss: 0.5331 - val_acc: 0.8236\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4734 - acc: 0.8337 - val_loss: 0.6816 - val_acc: 0.7852\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4665 - acc: 0.8364 - val_loss: 0.5306 - val_acc: 0.8197\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.4756 - acc: 0.8333 - val_loss: 0.6845 - val_acc: 0.7689\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4537 - acc: 0.8407 - val_loss: 0.7472 - val_acc: 0.7819\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.4585 - acc: 0.8406 - val_loss: 0.6150 - val_acc: 0.8151\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4615 - acc: 0.8368 - val_loss: 0.5295 - val_acc: 0.8294\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4547 - acc: 0.8385 - val_loss: 0.5971 - val_acc: 0.8034\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4536 - acc: 0.8393 - val_loss: 0.5420 - val_acc: 0.8086\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.4484 - acc: 0.8434 - val_loss: 0.5466 - val_acc: 0.8242\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4408 - acc: 0.8446 - val_loss: 0.4156 - val_acc: 0.8535\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4517 - acc: 0.8376 - val_loss: 0.5594 - val_acc: 0.8158\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 0.4463 - acc: 0.8437 - val_loss: 0.5528 - val_acc: 0.8158\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.4422 - acc: 0.8415 - val_loss: 0.5217 - val_acc: 0.8411\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 0.4341 - acc: 0.8434 - val_loss: 0.5502 - val_acc: 0.8210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f158409f128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD0BhaXT_7f1",
        "colab_type": "text"
      },
      "source": [
        "**Best Accuracy:**\n",
        "Epoch 46/50\n",
        "30/30 [==============================] - 5s 167ms/step - loss: 0.4408 - acc: 0.8446 - val_loss: 0.4156 - **val_acc: 0.8535**"
      ]
    }
  ]
}