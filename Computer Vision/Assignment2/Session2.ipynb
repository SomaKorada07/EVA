{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# **Not an ideal network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17ca7c13-83cf-435e-d28c-230849b3a407"
      },
      "source": [
        "# https://keras.io/\n",
        "# Installing Keras which is open-source neural-network library written in Python.\n",
        "!pip install -q keras\n",
        "\n",
        "# Importing the keras library.\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing NumPy (Numerical Python) which is a library consisting of multidimensional array objects and a collection of routines for processing those arrays. It also gives an alias to the library.\n",
        "import numpy as np\n",
        "\n",
        "# There are two main types of models available in Keras: the Sequential model and the Model class used with the functional API.\n",
        "# Sequential model is a linear stack of layers. Importing Sequential model from Keras.\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Flattens the input. Importing Flatten core layer from Keras.\n",
        "from keras.layers import Flatten\n",
        "\n",
        "# 2D Convolutional layer which creates a convolution kernel that convolves over input to produce an output. Importing the convolutional layer from Keras.\n",
        "from keras.layers import Convolution2D\n",
        "\n",
        "# Importing the utils library of Keras.\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# MNIST is a database of handwritten digits. It is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. Importing MNIST dataset from Keras.\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the MNIST 60000 Training and 10000 Test data into respective numpy arrays\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "e55cdbc6-75b4-4c22-c075-085c25f107e0"
      },
      "source": [
        "# Printing the shape of the Training data \n",
        "print (X_train.shape)\n",
        "\n",
        "# Matplotlib is a plotting library for Python. Pyplot is a collection of command style functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc.\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Sets the backend of matplotlib to 'inline' backend. With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it.\n",
        "%matplotlib inline\n",
        "\n",
        "# Renders the image.\n",
        "plt.imshow(X_train[59999])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f04060ed208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADqxJREFUeJzt3X+QVfV5x/HPAy4gPzQicUORBiHE\nlNqKuoW0sR2NmlFjC0aGkbSGtjTQVmqxmtSxf4R/OmXaoDE2scVIg06iycQwMgnTSLGWOqbIqhRQ\nIxC6Bjb8sgT50QjL+vSPPWRW3fPd673n3nN3n/drZmfvPc859zxzZj977j3fe+/X3F0A4hlSdgMA\nykH4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EdUYjdzbMhvsIjWrkLoFQ3tRxnfQTVsm6NYXf\nzK6VdJ+koZK+5u7LUuuP0CjNtKtq2SWAhI2+vuJ1q37ab2ZDJX1F0nWSpkmaZ2bTqn08AI1Vy2v+\nGZJ2uvsudz8p6TFJs4ppC0C91RL+CZJ297q/J1v2Nma20Mzazay9Sydq2B2AItX9ar+7r3D3Nndv\na9Hweu8OQIVqCX+npIm97p+fLQMwANQS/k2SpprZBWY2TNLNktYU0xaAeqt6qM/dT5nZYkk/UM9Q\n30p3f6mwzgDUVU3j/O6+VtLagnoB0EC8vRcIivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I\nivADQRF+ICjCDwRF+IGgapql18w6JB2V1C3plLu3FdEUgPqrKfyZK9399QIeB0AD8bQfCKrW8Luk\nJ83seTNbWERDABqj1qf9l7t7p5mdJ2mdmf3I3Tf0XiH7p7BQkkZoZI27A1CUms787t6Z/T4gabWk\nGX2ss8Ld29y9rUXDa9kdgAJVHX4zG2VmY07flvQJSduKagxAfdXytL9V0mozO/0433T3fy2kKwB1\nV3X43X2XpIsL7AWDkF32q7m17tHDanrsYR3pEeZTr+2u6fEHO4b6gKAIPxAU4QeCIvxAUIQfCIrw\nA0EV8ak+DGA/n/WuN2W+zeEp6T+RKz69KVm/87x/zq1NGFrb273vPzw5WX9y9qW5te4du2ra92DA\nmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcf5A7Pmdmsu5/cjBZf/HXvlPT/r//f+fl1p7qHl3T\nY3981I+S9flPvZxbm/epRcltfdPWZP2Miecn63vuH5OsXzjuQG7tjcv/N7ltUTjzA0ERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQjPMPAgf+/Ldya7ff9u3ktr8/Jn+8WZIuWb44WT/rJ93p+tM7c2vdr9c2\nnv2lv5iTrH/59q/m1n48J/0egw8f/OVk/eLVHcn6374v/T0HSxbnH9fhYpwfQB0RfiAowg8ERfiB\noAg/EBThB4Ii/EBQ5u7pFcxWSrpB0gF3vyhbNlbStyRNktQhaa67/6y/nZ1lY32mXVVjy/GcMXlS\nsv6p7/9Xbu3jI/PH2SXpxi9+Pln/wD+1J+vedTJZrydrSU/xvf1rF+XWXr36weS2/3PqzWT9YPeZ\nyfqt96bfH9F6/7PJerU2+nod8UNWybqVnPm/Lunadyy7S9J6d58qaX12H8AA0m/43X2DpEPvWDxL\n0qrs9ipJswvuC0CdVfuav9Xd92a390lqLagfAA1S8wU/77lokHvhwMwWmlm7mbV36UStuwNQkGrD\nv9/MxktS9jv30yHuvsLd29y9rUXDq9wdgKJVG/41kuZnt+dLeqKYdgA0Sr/hN7NHJf1Q0oVmtsfM\nFkhaJukaM9sh6ersPoABpN/P87v7vJwSA/YN8pM5v5SsLzh7X25t+t+lx/H7G29OvwukXLvvbEvW\nd1z9j4lqeij8z3bk/dn3GD7njWS99XB9xvGLxDv8gKAIPxAU4QeCIvxAUIQfCIrwA0Hx1d0DwLDf\nfj1Z33PqWG6tdePRott5T4aMHJlbO3TTxcltf3NJ+uuv7zl3ebK+vSt/oPLme+9MbjvhX7Yl691H\njiTrAwFnfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+AeDX3783Wb/ym5/LrU1+7oe17XzI0GT5\n5793WbI+8rbO3NqzF34lue2mE+kPFM96/PZkfcod+V9p/gGlP3Kbnnh8cODMDwRF+IGgCD8QFOEH\ngiL8QFCEHwiK8ANBMc4/AHS9lR5rv+aqF3NrHePOTW7bfehwsr53ycxk/cU7Ul+PLZ1KjJhPXfen\nyW0veCRZ1pT1+eP46B9nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iqt9xfjNbKekGSQfc/aJs2VJJ\nn5V0MFvtbndfW68mo3t200eS9S9d/3BubdnVn0lue9bC3cn6A5PS4/i/u/2GZP348vNza1O/91xy\nW9RXJWf+r0u6to/l97r79OyH4AMDTL/hd/cNkg41oBcADVTLa/7FZrbFzFaa2TmFdQSgIaoN/wOS\npkiaLmmvpNxJ08xsoZm1m1l7l05UuTsARasq/O6+39273f0tSQ9KmpFYd4W7t7l7W4uGV9sngIJV\nFX4zG9/r7o2S0lOaAmg6lQz1PSrpCknjzGyPpC9IusLMpktySR2SFtWxRwB10G/43X1eH4sfqkMv\nqNInRx7Lry3/anLb/3wz/Sew9DN/nKwPeWZzsj5CP03WUR7e4QcERfiBoAg/EBThB4Ii/EBQhB8I\niq/uboAhI0Yk64fmXpKsb7jxH/rZw8jcyvTn/iC55YS5O5P1IV3poTwMXJz5gaAIPxAU4QeCIvxA\nUIQfCIrwA0ERfiAoxvkboOPzlybr2xalvx77kaOTk/VbxuzLrZ186ezktt51MlnH4MWZHwiK8ANB\nEX4gKMIPBEX4gaAIPxAU4QeCYpy/ADu+PDNdvyk9jv8rG/4oWf/QF/K/mluSjq5uz62NTs/AjcA4\n8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP2O85vZREkPS2qV5JJWuPt9ZjZW0rckTZLUIWmuu/+s\nfq2W6/hN+WP5i658KrntR/4jPc31hz93oKqeTvuNM3fl1r7T2V3TY2PwquTMf0rSHe4+TdJHJd1q\nZtMk3SVpvbtPlbQ+uw9ggOg3/O6+191fyG4flfSKpAmSZklala22StLsejUJoHjv6TW/mU2SdImk\njZJa3X1vVtqnnpcFAAaIisNvZqMlPS5pibsf6V1zd1fP9YC+tltoZu1m1t6lEzU1C6A4FYXfzFrU\nE/xvuPt3s8X7zWx8Vh8vqc+rVu6+wt3b3L2tRcOL6BlAAfoNv5mZpIckveLu9/QqrZE0P7s9X9IT\nxbcHoF4q+UjvxyTdImmrmZ2er/luScskfdvMFkh6TdLc+rTYHDqvyx8yu3Psq8ltHxt1WbJ+qvOn\nyfrQcecm61tOTMytHVt0OLntiO8lyxjE+g2/uz8jyXLKVxXbDoBG4R1+QFCEHwiK8ANBEX4gKMIP\nBEX4gaD46u4Kve/FYfnF69Lbnn3mmzXt21pakvUpw/bn1rqfHNfPo2+voiMMBpz5gaAIPxAU4QeC\nIvxAUIQfCIrwA0ERfiAoxvkrNP4He3NrT/9Vehz+iWmPJuuz192crC/44NPJ+oUtb+TWznv+eHJb\nxMWZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCsp6ZthrjLBvrM23wfdv3kU9/NFmfdtu2ZP3MoV3J\n+trnpifrU2/dmKwjjo2+Xkf8UN5X7b8NZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrfcX4zmyjp\nYUmtklzSCne/z8yWSvqspIPZqne7+9rUYw3WcX6gWbyXcf5KvszjlKQ73P0FMxsj6XkzW5fV7nX3\nL1bbKIDy9Bt+d98raW92+6iZvSJpQr0bA1Bf7+k1v5lNknSJpNPvJ11sZlvMbKWZnZOzzUIzazez\n9i6dqKlZAMWpOPxmNlrS45KWuPsRSQ9ImiJpunqeGSzvazt3X+Hube7e1qLhBbQMoAgVhd/MWtQT\n/G+4+3clyd33u3u3u78l6UFJM+rXJoCi9Rt+MzNJD0l6xd3v6bV8fK/VbpSU/ugagKZSydX+j0m6\nRdJWM9ucLbtb0jwzm66e4b8OSYvq0iGAuqjkav8zkvoaN0yO6QNobrzDDwiK8ANBEX4gKMIPBEX4\ngaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFRDp+g2s4OSXuu1aJyk1xvWwHvTrL01\na18SvVWryN4+6O7vr2TFhob/XTs3a3f3ttIaSGjW3pq1L4neqlVWbzztB4Ii/EBQZYd/Rcn7T2nW\n3pq1L4neqlVKb6W+5gdQnrLP/ABKUkr4zexaM3vVzHaa2V1l9JDHzDrMbKuZbTaz9pJ7WWlmB8xs\nW69lY81snZntyH73OU1aSb0tNbPO7NhtNrPrS+ptopn9u5m9bGYvmdlfZstLPXaJvko5bg1/2m9m\nQyVtl3SNpD2SNkma5+4vN7SRHGbWIanN3UsfEzaz35F0TNLD7n5RtuzvJR1y92XZP85z3P2vm6S3\npZKOlT1zczahzPjeM0tLmi3pD1XisUv0NVclHLcyzvwzJO10913uflLSY5JmldBH03P3DZIOvWPx\nLEmrstur1PPH03A5vTUFd9/r7i9kt49KOj2zdKnHLtFXKcoI/wRJu3vd36PmmvLbJT1pZs+b2cKy\nm+lDazZtuiTtk9RaZjN96Hfm5kZ6x8zSTXPsqpnxumhc8Hu3y939UknXSbo1e3rblLznNVszDddU\nNHNzo/Qxs/QvlHnsqp3xumhlhL9T0sRe98/PljUFd+/Mfh+QtFrNN/vw/tOTpGa/D5Tczy8008zN\nfc0srSY4ds0043UZ4d8kaaqZXWBmwyTdLGlNCX28i5mNyi7EyMxGSfqEmm/24TWS5me350t6osRe\n3qZZZm7Om1laJR+7ppvx2t0b/iPpevVc8f+xpL8po4ecviZL+u/s56Wye5P0qHqeBnap59rIAknn\nSlovaYekf5M0tol6e0TSVklb1BO08SX1drl6ntJvkbQ5+7m+7GOX6KuU48Y7/ICguOAHBEX4gaAI\nPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wdRtXQGb2ORMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaping the Training and Test data to add the channel parameter as the input to Conv2D layer is expected to be of shape (img_rows, img_cols, num_channels) if data_format=\"channels_last\" which is default.\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing the Training and Test values \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b145e762-2575-4a39-8fa8-d42e4fffbcc5"
      },
      "source": [
        "# Printing the first 10 labelled Training data\n",
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "# np.utils.to_categorical is used to convert array of labelled data (from 0 to nb_classes-1) to one-hot vector.\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "13fcdc2d-c95c-4290-c923-aa91dfc332ef"
      },
      "source": [
        "# Printing the first 10 labelled Training data after converting to one-hot vector.\n",
        "Y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "7efd3f6f-71ce-41ea-b931-0492f098ff5a"
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "# Sequential model is linear stack of layers. We can add all the layers to the constructor or can use 'add' method to add layers.\n",
        "model = Sequential() \n",
        "\n",
        "# Input is (28,28,1).\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) # Receptive field is (3,3).\n",
        "\n",
        "# Input is (26,26,32).\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) # Receptive field is (5,5).\n",
        "\n",
        "# Input is (24,24,64).\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu')) # Receptive field is (7,7).\n",
        "\n",
        "# Input is (22,22,128).\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # Receptive field is (14,14).\n",
        "\n",
        "# Input is (11,11,128).\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu')) # Receptive field is (16,16).\n",
        "\n",
        "# Input is (9,9,256).\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu')) # Receptive field is (18,18).\n",
        "\n",
        "# Input is (7,7,512).\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu')) # Receptive field is (20,20).\n",
        "\n",
        "# Input is (5,5,1024).\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu')) # Receptive field is (22,22).\n",
        "\n",
        "# Input is (3,3,2048).\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # Receptive field is (24,24).\n",
        "\n",
        "# Input is (1,1,10).\n",
        "# Flattens the input.\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "# Loss function is one of the arguments required for compiling a model. categorical_crossentropy loss function is used if the targets are one-hot encoded.\n",
        "# Optimizer is one of the arguments required for compiling a model. Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n",
        "# A metric is a function that is used to judge the performance of your model.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "ad71eba6-8a64-421b-9992-ff44666b86da"
      },
      "source": [
        "# Training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10 , verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 117s 2ms/step - loss: 2.2268 - acc: 0.1374\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0402e78748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the model on the Test data. Returns the loss value & metrics values for the model in test mode.\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7eabf427-a6c6-44e3-ac66-d36818e3a22f"
      },
      "source": [
        "# Printing the evaluation result\n",
        "print(score)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3025851249694824, 0.098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates output predictions for the input samples.\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cd826a75-db57-4a8c-ccc5-6d1c7a56e079"
      },
      "source": [
        "# Printing the outputs. y_pred results do not look correct.\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL374YzDCETC",
        "colab_type": "text"
      },
      "source": [
        "# WHAT IS WRONG WITH THE ABOVE NETWORK\n",
        "  \n",
        "\n",
        "1.   Far too many number of kernels were used. As the input image size is 28x28x1, we could limit the network to use 64 or 128 number of kernels at max.\n",
        "2.   Global Receptive Field at the last layer (24X24) is not equal to the size of the image (considering size of the object is equal to size of the image which is 28x28).\n",
        "\n",
        "\n"
      ]
    }
  ]
}