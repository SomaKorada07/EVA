{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a215247-fde3-4cb1-a90a-6d4637bbe63d"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return (1 / (1 + np.exp(-x))) # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1 - y) # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return (2 * sigmoid(2 * x) - 1) # write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return ( 1 - (y * y)) # write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JswTYogEBQo0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99a95cbb-1990-40af-e96b-11e12f099a6c"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqgQh8BjBwxF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fedcdfab-0283-4256-d390-4c5f9973b31e"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1__kggu4BzlK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "938b306d-b795-4334-ced3-a3415a5b2844"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2449186624037092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5KttO3vB359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c99cfe92-2b1a-42f1-c181-3656247d2fba"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.add(np.dot(p.W_f.v, z), p.b_f.v)) # write your code here\n",
        "    i = sigmoid(np.add(np.dot(p.W_i.v, z), p.b_i.v)) # write your code here\n",
        "    C_bar = tanh(np.add(np.dot(p.W_C.v, z), p.b_C.v)) # write your code here\n",
        "\n",
        "    C = np.add(f*C_prev, i*C_bar) # write your code here\n",
        "    o = sigmoid(np.add(np.dot(p.W_o.v, z), p.b_o.v)) # write your code here\n",
        "    h = o*tanh(C) # write your code here\n",
        "\n",
        "    v = np.add(np.dot(p.W_v.v, h), p.b_v.v) # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RckUtcsJn0y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fa5d44c-67f2-4a86-8965-d4423a34fd7d"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLIZEsA1JzYo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eafc6d5e-ecd7-4b07-f65e-55b18bf485b5"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9F4XH9BJ4I_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45d95c2e-b66b-4c9c-a31a-54b62d48be46"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNKRdltxJ9c_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ba49d26-4ca0-4672-af2d-4043a4e676bf"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46.588178640611375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "034dc701-1a37-4860-8330-068b2a5dfe0c"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " est sare vaccines ame fouth reported that countries infected the 1960s but sume coronavirus can wese retentious the Arabimated ne testical other with the 19D0r hed coronavirus close symptoms, such a f \n",
            "----\n",
            "iter 49900, loss 3.963252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}